{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>target</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_02</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1674.45058</td>\n",
       "      <td>5888.20750</td>\n",
       "      <td>16.773757</td>\n",
       "      <td>0.933841</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.682270</td>\n",
       "      <td>24.734743</td>\n",
       "      <td>0.292039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1736.99230</td>\n",
       "      <td>6735.33812</td>\n",
       "      <td>21.496661</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.119311</td>\n",
       "      <td>24.757737</td>\n",
       "      <td>3.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2403.57591</td>\n",
       "      <td>7273.04995</td>\n",
       "      <td>10.931425</td>\n",
       "      <td>0.810545</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083010</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.142276</td>\n",
       "      <td>25.094093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1740.78737</td>\n",
       "      <td>5734.49046</td>\n",
       "      <td>23.119257</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.372052</td>\n",
       "      <td>24.942867</td>\n",
       "      <td>2.038778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1730.51451</td>\n",
       "      <td>6657.23835</td>\n",
       "      <td>13.652252</td>\n",
       "      <td>0.950575</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.409381</td>\n",
       "      <td>25.290165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_households  total_individuals     target     dw_00     dw_01  \\\n",
       "0        1674.45058         5888.20750  16.773757  0.933841  0.000846   \n",
       "1        1736.99230         6735.33812  21.496661  0.696940  0.001253   \n",
       "2        2403.57591         7273.04995  10.931425  0.810545  0.004517   \n",
       "3        1740.78737         5734.49046  23.119257  0.659914  0.000000   \n",
       "4        1730.51451         6657.23835  13.652252  0.950575  0.000655   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...     pw_02     pw_03  \\\n",
       "0  0.005490  0.000676  0.000000  0.001372  0.005750  ...  0.019968  0.002848   \n",
       "1  0.004402  0.000000  0.002301  0.001323  0.007575  ...  0.018946  0.014566   \n",
       "2  0.008891  0.003986  0.007735  0.000956  0.006686  ...  0.083010  0.057560   \n",
       "3  0.006129  0.000000  0.000813  0.037245  0.005255  ...  0.002689  0.000000   \n",
       "4  0.001473  0.000598  0.006999  0.000818  0.004985  ...  0.009699  0.004859   \n",
       "\n",
       "      pw_04     pw_05     pw_06  pw_07  pw_08        lat        lon        NL  \n",
       "0  0.007537  0.000000  0.012928      0      0 -29.682270  24.734743  0.292039  \n",
       "1  0.057127  0.019092  0.004131      0      0 -29.119311  24.757737  3.207775  \n",
       "2  0.010358  0.001421  0.040881      0      0 -29.142276  25.094093  0.000000  \n",
       "3  0.000669  0.000000  0.005011      0      0 -29.372052  24.942867  2.038778  \n",
       "4  0.001290  0.000673  0.017629      0      0 -29.409381  25.290165  0.000000  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women = pd.read_csv(\"data/sa_women.2.clean.csv\")\n",
    "women.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_households', 'total_individuals', 'target', 'dw_00', 'dw_01',\n",
       "       'dw_02', 'dw_03', 'dw_04', 'dw_05', 'dw_06', 'dw_07', 'dw_08', 'dw_09',\n",
       "       'dw_10', 'dw_11', 'dw_12', 'dw_13', 'psa_00', 'psa_01', 'psa_02',\n",
       "       'psa_03', 'psa_04', 'stv_00', 'car_00', 'lln_00', 'lan_00', 'lan_01',\n",
       "       'lan_02', 'lan_03', 'lan_04', 'lan_05', 'lan_06', 'lan_07', 'lan_08',\n",
       "       'lan_09', 'lan_10', 'lan_11', 'lan_12', 'lan_13', 'lan_14', 'pg_00',\n",
       "       'pg_01', 'pg_02', 'pg_03', 'pg_04', 'lgt_00', 'pw_00', 'pw_01', 'pw_02',\n",
       "       'pw_03', 'pw_04', 'pw_05', 'pw_06', 'pw_07', 'pw_08', 'lat', 'lon',\n",
       "       'NL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's begin by making a validation set to test the multiple types of models on\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = women.drop(\"target\", axis=1)\n",
    "y = women[\"target\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression on the base data set:\n",
      "0.8576268108992714\n",
      "3.909750875419991\n"
     ]
    }
   ],
   "source": [
    "## At the start we're going to run a basic linear regression on the raw X_train data to get a baseline idea about\n",
    "## model performance\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"Linear regression on the base data set:\")\n",
    "\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "print(cross_val_score(estimator=linreg, X=X_train, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=linreg, X=X_train, y=y_train, scoring=\"neg_mean_squared_error\").mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data with regular linear regression:\n",
      "Standard Scaled R^2: -5.089423412521885\n",
      "Robust Scaled R^2: 0.8571139104845855\n",
      "Power Scaled R^2: -5.053218528586572\n"
     ]
    }
   ],
   "source": [
    "## We see that a basic linear regression already outputs a good prediction, explaining a lot of the model's variance.\n",
    "## Let's try scaling the input features and using different models to see if we can improve on it\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, power_transform\n",
    "\n",
    "stan_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "X_train_stanscale = stan_scaler.fit_transform(X_train)\n",
    "X_train_robscale = rob_scaler.fit_transform(X_train)\n",
    "X_train_powscale = power_transform(X=X_train, method='yeo-johnson')\n",
    "\n",
    "print(\"Scaled data with regular linear regression:\")\n",
    "\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_stanscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_powscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaled R^2: 0.7932164348774753\n",
      "Robust Scaled R^2: 0.7866920136128908\n",
      "Power Scaled R^2: 0.8096108087204051\n"
     ]
    }
   ],
   "source": [
    "## Let's see how a regularized linear model does on the different standardized datasets\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "net = ElasticNet()\n",
    "\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=net, X=X_train_stanscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=net, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=net, X=X_train_powscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial features, elastic net:\n",
      "Unscaled R^2: 0.8458208727022052\n",
      "Standard Scaled R^2: 0.8178356698038547\n",
      "Robust Scaled R^2: 0.8125564614236602\n",
      "Power Scaled R^2: 0.8354024445294448\n"
     ]
    }
   ],
   "source": [
    "## Let's see if polynomial features increases model performance\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_train_polystan = poly.fit_transform(X_train_stanscale)\n",
    "X_train_polyrob = poly.fit_transform(X_train_robscale)\n",
    "X_train_polypow = poly.fit_transform(X_train_powscale)\n",
    "\n",
    "## First let's try the polynomial features with the elasticnet regressor\n",
    "\n",
    "print(\"With polynomial features, elastic net:\")\n",
    "\n",
    "print(\"Unscaled R^2:\", cross_val_score(estimator=net, X=X_train_poly, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polystan, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polyrob, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polypow, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features with regular linear regression\n",
      "Unscaled R^2: -2.985200643007221\n",
      "Standard Scaled R^2: -65.35270332952197\n",
      "Robust Scaled R^2: -54.777408061260225\n",
      "Power Scaled R^2: 0.32446339357296083\n"
     ]
    }
   ],
   "source": [
    "## Now with the regular linear regression\n",
    "print(\"Polynomial features with regular linear regression\")\n",
    "print(\"Unscaled R^2:\", cross_val_score(estimator=linreg, X=X_train_poly, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polystan, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polyrob, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polypow, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression's performance on the validation set:\n",
      "{'unscaled_linreg': 0.8592054386963557}\n",
      "{'unscaled_linreg': 3.726941696442016}\n"
     ]
    }
   ],
   "source": [
    "## It seems our best performance with a linear regressor was with the unscaled X_train with vanilla linear regression.\n",
    "## Let's check and save its performance on the validation set\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "valid_r2 = {}\n",
    "valid_rmse = {}\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "predictions = linreg.predict(X_valid)\n",
    "\n",
    "valid_r2[\"unscaled_linreg\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"unscaled_linreg\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(\"Linear regression's performance on the validation set:\")\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\n",
      "0.8774508434485696\n",
      "3.6422804609833395\n"
     ]
    }
   ],
   "source": [
    "## Now let's see how a random forest performs on this data, and this can also give us some idea of feature importances\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "print(\"Random forest:\")\n",
    "print(cross_val_score(estimator=forest, X=X_train, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=forest, X=X_train, y=y_train, scoring=\"neg_mean_squared_error\", cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00218614, 0.00255499, 0.00267956, 0.00432479, 0.00281835,\n",
       "       0.00174957, 0.00158875, 0.00179831, 0.00247225, 0.00269799,\n",
       "       0.00275604, 0.00195806, 0.00146929, 0.00309955, 0.        ,\n",
       "       0.        , 0.57607372, 0.00639669, 0.00196505, 0.00217788,\n",
       "       0.005652  , 0.00432249, 0.20044678, 0.01199845, 0.00324895,\n",
       "       0.00315159, 0.0021525 , 0.00510636, 0.00357126, 0.00366679,\n",
       "       0.00424451, 0.00433272, 0.00265586, 0.00400614, 0.00311076,\n",
       "       0.00497131, 0.00273008, 0.        , 0.00133011, 0.00872881,\n",
       "       0.00506755, 0.00279782, 0.00523709, 0.0030801 , 0.00295414,\n",
       "       0.04679625, 0.00310661, 0.00337593, 0.00234871, 0.00249449,\n",
       "       0.00185137, 0.0023738 , 0.        , 0.        , 0.00497006,\n",
       "       0.00869577, 0.00465585])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wow, this is very promising! Out of the box, the random forest does better on cross validation than linear regression\n",
    "## Now, let's see the random forest model's feature importances\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>psa_00</th>\n",
       "      <td>0.576074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_00</th>\n",
       "      <td>0.200447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pw_00</th>\n",
       "      <td>0.046796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lln_00</th>\n",
       "      <td>0.011998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg_00</th>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_importance\n",
       "psa_00            0.576074\n",
       "car_00            0.200447\n",
       "pw_00             0.046796\n",
       "lln_00            0.011998\n",
       "pg_00             0.008729"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = {feature: importance for feature, importance in zip(X_train.columns, forest.feature_importances_)}\n",
    "feature_importances = pd.DataFrame.from_dict(importances, orient='index', columns=[\"feature_importance\"])\n",
    "feature_importances.sort_values(\"feature_importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's try using grid search to optimize the random forest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "forestgrid = {\n",
    "    \"n_estimators\": [10, 50, 100, 1000, 10000],\n",
    "    \"max_depth\": [3, 4, 5, 6, None],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "grid = GridSearchCV(estimator=forest, param_grid=forestgrid, scoring=\"r2\", n_jobs=-1, verbose=2, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 30.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [3, 4, 5, 6, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 50, 100, 1000, 10000]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 10000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765206234057411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unscaled_linreg': 0.8592054386963557, 'optimized_forest': 0.8901687135107363}\n",
      "{'unscaled_linreg': 3.726941696442016, 'optimized_forest': 3.291718548192841}\n"
     ]
    }
   ],
   "source": [
    "## Now that we have optimized hyperparameters for the random forest, let's evaluate its importance.\n",
    "\n",
    "best_forest = RandomForestRegressor(bootstrap=False, max_depth=None, max_features='sqrt', n_estimators=10000)\n",
    "\n",
    "best_forest.fit(X_train, y_train)\n",
    "predictions = best_forest.predict(X_valid)\n",
    "\n",
    "valid_r2[\"optimized_forest\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"optimized_forest\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8574056842129044\n",
      "3.914679087104853\n"
     ]
    }
   ],
   "source": [
    "##Now, let's explore other potential regression model candidates, and find the most promising ones using cv score\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svreg = svm.SVR(kernel='linear')\n",
    "\n",
    "print(cross_val_score(estimator=svreg, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=svreg, X=X_train_robscale, y=y_train, scoring=\"neg_mean_squared_error\", cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8887914495174044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=1000)\n",
    "\n",
    "print(cross_val_score(estimator=gb, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 20.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000286EA4B5148>,\n",
       "                                        'max_depth': [2, 3, 4, 5],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'n_estimators': [100, 1000, 10000]},\n",
       "                   scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The gradient boosting regressor seems incredibly alluring with that cross-val score! So let's optimize the \n",
    "## hyperparameters using RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "gb_grid = {\n",
    "    \"n_estimators\": [100, 1000, 10000],\n",
    "    \"learning_rate\": loguniform(0.001, 1),\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "rand = RandomizedSearchCV(estimator=gb, param_distributions=gb_grid, scoring=\"r2\", n_jobs=-1, \n",
    "                          verbose=2, cv=3, n_iter=100)\n",
    "\n",
    "rand.fit(X_train_robscale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005557832351846306,\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 10000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922381016522563"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unscaled_linreg': 0.8592054386963557, 'optimized_forest': 0.8901687135107363, 'optimized_gradboost': 0.9046246723318132, 'optimized_baggingextratrees': 0.8950191309619571}\n",
      "{'unscaled_linreg': 3.726941696442016, 'optimized_forest': 3.291718548192841, 'optimized_gradboost': 3.067451331003651, 'optimized_baggingextratrees': 3.218212675846616}\n"
     ]
    }
   ],
   "source": [
    "## Now let's evaluate the optimized gradient boosting regressor on the validation set\n",
    "## Since we used the robustly scaled data to find the optimized hyperparameters, we will use robust scaling on the\n",
    "## validation set to evaluate the model's performance\n",
    "\n",
    "X_valid_robscale = rob_scaler.transform(X_valid)\n",
    "\n",
    "best_gb = GradientBoostingRegressor(learning_rate=0.0056, max_depth=5, max_features='sqrt', n_estimators=10000)\n",
    "\n",
    "best_gb.fit(X_train_robscale, y_train)\n",
    "predictions = best_gb.predict(X_valid_robscale)\n",
    "\n",
    "valid_r2[\"optimized_gradboost\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"optimized_gradboost\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85538074694879\n"
     ]
    }
   ],
   "source": [
    "## We see the gradient boosting model has even better performance on the validation set! Before we wrap up, let's see\n",
    "## if there are any other distinctly promising models\n",
    "\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "psr = PoissonRegressor(alpha=0.5)\n",
    "\n",
    "print(cross_val_score(estimator=psr, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576030284557467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rid = Ridge()\n",
    "\n",
    "print(cross_val_score(estimator=rid, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576069179706138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "bayrid = BayesianRidge()\n",
    "\n",
    "print(cross_val_score(estimator=bayrid, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883311250520606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "estimator_bagging_random_tree_1000 = BaggingRegressor(n_estimators=1000,\n",
    "                                    base_estimator=ExtraTreeRegressor())\n",
    "print(cross_val_score(estimator=estimator_bagging_random_tree_1000, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=BaggingRegressor(base_estimator=ExtraTreeRegressor(),\n",
       "                                        n_estimators=1000),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'bootstrap_features': [True, False],\n",
       "                         'n_estimators': [10, 50, 100, 1000, 10000]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The Bagging Regressor, using the Extra Trees Regressor as the base estimator, gives us \n",
    "\n",
    "bagtreeparams = {\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"bootstrap_features\": [True, False],\n",
    "    \"n_estimators\": [10, 50, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "bagtree_reg = BaggingRegressor(n_estimators=1000, base_estimator=ExtraTreeRegressor())\n",
    "\n",
    "bagtree_grid = GridSearchCV(estimator=bagtree_reg, param_grid=bagtreeparams, scoring=\"r2\", n_jobs=-1, verbose=2, cv=3)\n",
    "bagtree_grid.fit(X_train_robscale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 10000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8848817579887772"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtree_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unscaled_linreg': 0.8592054386963557, 'optimized_forest': 0.8901687135107363, 'optimized_gradboost': 0.9046246723318132, 'optimized_baggingextratrees': 0.8954026174887673}\n",
      "{'unscaled_linreg': 3.726941696442016, 'optimized_forest': 3.291718548192841, 'optimized_gradboost': 3.067451331003651, 'optimized_baggingextratrees': 3.212329364294906}\n"
     ]
    }
   ],
   "source": [
    "best_bagtree = BaggingRegressor(n_estimators=10000, bootstrap=False, base_estimator=ExtraTreeRegressor())\n",
    "\n",
    "best_bagtree.fit(X_train_robscale, y_train)\n",
    "predictions = best_bagtree.predict(X_valid_robscale)\n",
    "\n",
    "valid_r2[\"optimized_baggingextratrees\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"optimized_baggingextratrees\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.0056, max_depth=5,\n",
       "                          max_features='sqrt', n_estimators=10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## So we see that the gradientboostingregressor offers us the best performance on the validation set, and so we will \n",
    "## use this to generate predictions on the test set\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "Xtrain_robscale = rob_scaler.fit_transform(X)\n",
    "\n",
    "best_gb = GradientBoostingRegressor(learning_rate=0.0056, max_depth=5, max_features='sqrt', n_estimators=10000)\n",
    "\n",
    "best_gb.fit(Xtrain_robscale, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>ADM4_PCODE</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21001001: Ward 1</td>\n",
       "      <td>2504.95194</td>\n",
       "      <td>8745.15151</td>\n",
       "      <td>0.947257</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZA2101001</td>\n",
       "      <td>-32.637758</td>\n",
       "      <td>23.848688</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21001002: Ward 2</td>\n",
       "      <td>2080.27718</td>\n",
       "      <td>7258.11764</td>\n",
       "      <td>0.844993</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZA2101002</td>\n",
       "      <td>-31.990536</td>\n",
       "      <td>24.555818</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21001003: Ward 3</td>\n",
       "      <td>1106.62639</td>\n",
       "      <td>5919.13170</td>\n",
       "      <td>0.651380</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.259711</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZA2101003</td>\n",
       "      <td>-32.283595</td>\n",
       "      <td>24.563940</td>\n",
       "      <td>8.269556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21001004: Ward 4</td>\n",
       "      <td>2175.56096</td>\n",
       "      <td>10280.57452</td>\n",
       "      <td>0.410837</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449604</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZA2101004</td>\n",
       "      <td>-32.261612</td>\n",
       "      <td>24.542202</td>\n",
       "      <td>8.626625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21001005: Ward 5</td>\n",
       "      <td>1270.83883</td>\n",
       "      <td>6018.34202</td>\n",
       "      <td>0.942851</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZA2101005</td>\n",
       "      <td>-32.251571</td>\n",
       "      <td>24.558537</td>\n",
       "      <td>8.601754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ward  total_households  total_individuals     dw_00     dw_01  \\\n",
       "0  21001001: Ward 1        2504.95194         8745.15151  0.947257  0.000873   \n",
       "1  21001002: Ward 2        2080.27718         7258.11764  0.844993  0.000481   \n",
       "2  21001003: Ward 3        1106.62639         5919.13170  0.651380  0.007937   \n",
       "3  21001004: Ward 4        2175.56096        10280.57452  0.410837  0.002468   \n",
       "4  21001005: Ward 5        1270.83883         6018.34202  0.942851  0.002638   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...     pw_03     pw_04  \\\n",
       "0  0.002021  0.000000  0.000000  0.030116  0.000452  ...  0.001757  0.000000   \n",
       "1  0.043629  0.004714  0.012323  0.012300  0.022132  ...  0.000691  0.000000   \n",
       "2  0.007113  0.000000  0.001977  0.259711  0.006505  ...  0.002253  0.000000   \n",
       "3  0.011511  0.000485  0.000000  0.449604  0.009256  ...  0.000000  0.000661   \n",
       "4  0.000821  0.000000  0.000891  0.000787  0.000830  ...  0.000000  0.000000   \n",
       "\n",
       "   pw_05     pw_06  pw_07  pw_08  ADM4_PCODE        lat        lon        NL  \n",
       "0    0.0  0.006649    0.0    0.0   ZA2101001 -32.637758  23.848688  0.000000  \n",
       "1    0.0  0.002916    0.0    0.0   ZA2101002 -31.990536  24.555818  0.000000  \n",
       "2    0.0  0.000000    0.0    0.0   ZA2101003 -32.283595  24.563940  8.269556  \n",
       "3    0.0  0.001379    0.0    0.0   ZA2101004 -32.261612  24.542202  8.626625  \n",
       "4    0.0  0.001660    0.0    0.0   ZA2101005 -32.251571  24.558537  8.601754  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's bring in the test set\n",
    "\n",
    "test_set = pd.read_csv(\"data/test.csv\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ward', 'total_households', 'total_individuals', 'dw_00', 'dw_01',\n",
       "       'dw_02', 'dw_03', 'dw_04', 'dw_05', 'dw_06', 'dw_07', 'dw_08', 'dw_09',\n",
       "       'dw_10', 'dw_11', 'dw_12', 'dw_13', 'psa_00', 'psa_01', 'psa_02',\n",
       "       'psa_03', 'psa_04', 'stv_00', 'stv_01', 'car_00', 'car_01', 'lln_00',\n",
       "       'lln_01', 'lan_00', 'lan_01', 'lan_02', 'lan_03', 'lan_04', 'lan_05',\n",
       "       'lan_06', 'lan_07', 'lan_08', 'lan_09', 'lan_10', 'lan_11', 'lan_12',\n",
       "       'lan_13', 'lan_14', 'pg_00', 'pg_01', 'pg_02', 'pg_03', 'pg_04',\n",
       "       'lgt_00', 'pw_00', 'pw_01', 'pw_02', 'pw_03', 'pw_04', 'pw_05', 'pw_06',\n",
       "       'pw_07', 'pw_08', 'ADM4_PCODE', 'lat', 'lon', 'NL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now let's transform and scale the test set so that the optimized gradient boosting model will work on it\n",
    "test_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.set_index(\"ward\")\n",
    "test_set = test_set.drop([\"stv_01\", \"car_01\", \"lln_01\", \"ADM4_PCODE\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 58)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward</th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21001001: Ward 1</td>\n",
       "      <td>2504.95194</td>\n",
       "      <td>8745.15151</td>\n",
       "      <td>0.947257</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030116</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.637758</td>\n",
       "      <td>23.848688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.570097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21001002: Ward 2</td>\n",
       "      <td>2080.27718</td>\n",
       "      <td>7258.11764</td>\n",
       "      <td>0.844993</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.043629</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-31.990536</td>\n",
       "      <td>24.555818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.068645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21001003: Ward 3</td>\n",
       "      <td>1106.62639</td>\n",
       "      <td>5919.13170</td>\n",
       "      <td>0.651380</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.259711</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.283595</td>\n",
       "      <td>24.563940</td>\n",
       "      <td>8.269556</td>\n",
       "      <td>21.137121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21001004: Ward 4</td>\n",
       "      <td>2175.56096</td>\n",
       "      <td>10280.57452</td>\n",
       "      <td>0.410837</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449604</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.261612</td>\n",
       "      <td>24.542202</td>\n",
       "      <td>8.626625</td>\n",
       "      <td>16.487480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21001005: Ward 5</td>\n",
       "      <td>1270.83883</td>\n",
       "      <td>6018.34202</td>\n",
       "      <td>0.942851</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.251571</td>\n",
       "      <td>24.558537</td>\n",
       "      <td>8.601754</td>\n",
       "      <td>20.935502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ward  total_households  total_individuals     dw_00     dw_01  \\\n",
       "0  21001001: Ward 1        2504.95194         8745.15151  0.947257  0.000873   \n",
       "1  21001002: Ward 2        2080.27718         7258.11764  0.844993  0.000481   \n",
       "2  21001003: Ward 3        1106.62639         5919.13170  0.651380  0.007937   \n",
       "3  21001004: Ward 4        2175.56096        10280.57452  0.410837  0.002468   \n",
       "4  21001005: Ward 5        1270.83883         6018.34202  0.942851  0.002638   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...     pw_03     pw_04  \\\n",
       "0  0.002021  0.000000  0.000000  0.030116  0.000452  ...  0.001757  0.000000   \n",
       "1  0.043629  0.004714  0.012323  0.012300  0.022132  ...  0.000691  0.000000   \n",
       "2  0.007113  0.000000  0.001977  0.259711  0.006505  ...  0.002253  0.000000   \n",
       "3  0.011511  0.000485  0.000000  0.449604  0.009256  ...  0.000000  0.000661   \n",
       "4  0.000821  0.000000  0.000891  0.000787  0.000830  ...  0.000000  0.000000   \n",
       "\n",
       "   pw_05     pw_06  pw_07  pw_08        lat        lon        NL     target  \n",
       "0    0.0  0.006649    0.0    0.0 -32.637758  23.848688  0.000000  17.570097  \n",
       "1    0.0  0.002916    0.0    0.0 -31.990536  24.555818  0.000000  13.068645  \n",
       "2    0.0  0.000000    0.0    0.0 -32.283595  24.563940  8.269556  21.137121  \n",
       "3    0.0  0.001379    0.0    0.0 -32.261612  24.542202  8.626625  16.487480  \n",
       "4    0.0  0.001660    0.0    0.0 -32.251571  24.558537  8.601754  20.935502  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = test_set.reset_index()\n",
    "Xtest.drop([\"index\", \"ward\"], axis=1, inplace=True)\n",
    "Xtest_robscale = rob_scaler.transform(Xtest)\n",
    "\n",
    "## Let's make our predictions \n",
    "\n",
    "predictions = best_gb.predict(Xtest_robscale)\n",
    "\n",
    "test_set[\"target\"] = predictions\n",
    "\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## And now output into the format that Zindi expects\n",
    "test_set[[\"ward\", \"target\"]].set_index(\"ward\").to_csv(\"data/davshimsubmission1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
