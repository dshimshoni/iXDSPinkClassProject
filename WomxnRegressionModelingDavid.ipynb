{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_households</th>\n",
       "      <th>total_individuals</th>\n",
       "      <th>target</th>\n",
       "      <th>dw_00</th>\n",
       "      <th>dw_01</th>\n",
       "      <th>dw_02</th>\n",
       "      <th>dw_03</th>\n",
       "      <th>dw_04</th>\n",
       "      <th>dw_05</th>\n",
       "      <th>dw_06</th>\n",
       "      <th>...</th>\n",
       "      <th>pw_02</th>\n",
       "      <th>pw_03</th>\n",
       "      <th>pw_04</th>\n",
       "      <th>pw_05</th>\n",
       "      <th>pw_06</th>\n",
       "      <th>pw_07</th>\n",
       "      <th>pw_08</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1674.45058</td>\n",
       "      <td>5888.20750</td>\n",
       "      <td>16.773757</td>\n",
       "      <td>0.933841</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.682270</td>\n",
       "      <td>24.734743</td>\n",
       "      <td>0.292039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1736.99230</td>\n",
       "      <td>6735.33812</td>\n",
       "      <td>21.496661</td>\n",
       "      <td>0.696940</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.119311</td>\n",
       "      <td>24.757737</td>\n",
       "      <td>3.207775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2403.57591</td>\n",
       "      <td>7273.04995</td>\n",
       "      <td>10.931425</td>\n",
       "      <td>0.810545</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083010</td>\n",
       "      <td>0.057560</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.040881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.142276</td>\n",
       "      <td>25.094093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1740.78737</td>\n",
       "      <td>5734.49046</td>\n",
       "      <td>23.119257</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.372052</td>\n",
       "      <td>24.942867</td>\n",
       "      <td>2.038778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1730.51451</td>\n",
       "      <td>6657.23835</td>\n",
       "      <td>13.652252</td>\n",
       "      <td>0.950575</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-29.409381</td>\n",
       "      <td>25.290165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_households  total_individuals     target     dw_00     dw_01  \\\n",
       "0        1674.45058         5888.20750  16.773757  0.933841  0.000846   \n",
       "1        1736.99230         6735.33812  21.496661  0.696940  0.001253   \n",
       "2        2403.57591         7273.04995  10.931425  0.810545  0.004517   \n",
       "3        1740.78737         5734.49046  23.119257  0.659914  0.000000   \n",
       "4        1730.51451         6657.23835  13.652252  0.950575  0.000655   \n",
       "\n",
       "      dw_02     dw_03     dw_04     dw_05     dw_06  ...     pw_02     pw_03  \\\n",
       "0  0.005490  0.000676  0.000000  0.001372  0.005750  ...  0.019968  0.002848   \n",
       "1  0.004402  0.000000  0.002301  0.001323  0.007575  ...  0.018946  0.014566   \n",
       "2  0.008891  0.003986  0.007735  0.000956  0.006686  ...  0.083010  0.057560   \n",
       "3  0.006129  0.000000  0.000813  0.037245  0.005255  ...  0.002689  0.000000   \n",
       "4  0.001473  0.000598  0.006999  0.000818  0.004985  ...  0.009699  0.004859   \n",
       "\n",
       "      pw_04     pw_05     pw_06  pw_07  pw_08        lat        lon        NL  \n",
       "0  0.007537  0.000000  0.012928      0      0 -29.682270  24.734743  0.292039  \n",
       "1  0.057127  0.019092  0.004131      0      0 -29.119311  24.757737  3.207775  \n",
       "2  0.010358  0.001421  0.040881      0      0 -29.142276  25.094093  0.000000  \n",
       "3  0.000669  0.000000  0.005011      0      0 -29.372052  24.942867  2.038778  \n",
       "4  0.001290  0.000673  0.017629      0      0 -29.409381  25.290165  0.000000  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women = pd.read_csv(\"data/sa_women.2.clean.csv\")\n",
    "women.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_households', 'total_individuals', 'target', 'dw_00', 'dw_01',\n",
       "       'dw_02', 'dw_03', 'dw_04', 'dw_05', 'dw_06', 'dw_07', 'dw_08', 'dw_09',\n",
       "       'dw_10', 'dw_11', 'dw_12', 'dw_13', 'psa_00', 'psa_01', 'psa_02',\n",
       "       'psa_03', 'psa_04', 'stv_00', 'car_00', 'lln_00', 'lan_00', 'lan_01',\n",
       "       'lan_02', 'lan_03', 'lan_04', 'lan_05', 'lan_06', 'lan_07', 'lan_08',\n",
       "       'lan_09', 'lan_10', 'lan_11', 'lan_12', 'lan_13', 'lan_14', 'pg_00',\n",
       "       'pg_01', 'pg_02', 'pg_03', 'pg_04', 'lgt_00', 'pw_00', 'pw_01', 'pw_02',\n",
       "       'pw_03', 'pw_04', 'pw_05', 'pw_06', 'pw_07', 'pw_08', 'lat', 'lon',\n",
       "       'NL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's begin by making a validation set to test the multiple types of models on\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = women.drop(\"target\", axis=1)\n",
    "y = women[\"target\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression on the base data set:\n",
      "0.8576268108992714\n",
      "3.909750875419991\n"
     ]
    }
   ],
   "source": [
    "## At the start we're going to run a basic linear regression on the raw X_train data to get a baseline idea about\n",
    "## model performance\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"Linear regression on the base data set:\")\n",
    "\n",
    "linreg = LinearRegression(fit_intercept=False)\n",
    "print(cross_val_score(estimator=linreg, X=X_train, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=linreg, X=X_train, y=y_train, scoring=\"neg_mean_squared_error\").mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data with regular linear regression:\n",
      "Standard Scaled R^2: -5.089423412521885\n",
      "Robust Scaled R^2: 0.8571139104845855\n",
      "Power Scaled R^2: -5.053218528586572\n"
     ]
    }
   ],
   "source": [
    "## We see that a basic linear regression already outputs a good prediction, explaining a lot of the model's variance.\n",
    "## Let's try scaling the input features and using different models to see if we can improve on it\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, power_transform\n",
    "\n",
    "stan_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "X_train_stanscale = stan_scaler.fit_transform(X_train)\n",
    "X_train_robscale = rob_scaler.fit_transform(X_train)\n",
    "X_train_powscale = power_transform(X=X_train, method='yeo-johnson')\n",
    "\n",
    "print(\"Scaled data with regular linear regression:\")\n",
    "\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_stanscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_powscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaled R^2: 0.7932164348774753\n",
      "Robust Scaled R^2: 0.7866920136128908\n",
      "Power Scaled R^2: 0.8096108087204051\n"
     ]
    }
   ],
   "source": [
    "## Let's see how a regularized linear model does on the different standardized datasets\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "net = ElasticNet()\n",
    "\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=net, X=X_train_stanscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=net, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=net, X=X_train_powscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial features, elastic net:\n",
      "Unscaled R^2: 0.8458208727022052\n",
      "Standard Scaled R^2: 0.8178356698038547\n",
      "Robust Scaled R^2: 0.8125564614236602\n",
      "Power Scaled R^2: 0.8354024445294448\n"
     ]
    }
   ],
   "source": [
    "## Let's see if polynomial features increases model performance\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_train_polystan = poly.fit_transform(X_train_stanscale)\n",
    "X_train_polyrob = poly.fit_transform(X_train_robscale)\n",
    "X_train_polypow = poly.fit_transform(X_train_powscale)\n",
    "\n",
    "## First let's try the polynomial features with the elasticnet regressor\n",
    "\n",
    "print(\"With polynomial features, elastic net:\")\n",
    "\n",
    "print(\"Unscaled R^2:\", cross_val_score(estimator=net, X=X_train_poly, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polystan, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polyrob, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=net, X=X_train_polypow, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial features with regular linear regression\n",
      "Unscaled R^2: -2.985200643007221\n",
      "Standard Scaled R^2: -65.35270332952197\n",
      "Robust Scaled R^2: -54.777408061260225\n",
      "Power Scaled R^2: 0.32446339357296083\n"
     ]
    }
   ],
   "source": [
    "## Now with the regular linear regression\n",
    "print(\"Polynomial features with regular linear regression\")\n",
    "print(\"Unscaled R^2:\", cross_val_score(estimator=linreg, X=X_train_poly, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Standard Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polystan, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Robust Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polyrob, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(\"Power Scaled R^2:\", cross_val_score(estimator=linreg, X=X_train_polypow, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression's performance on the validation set:\n",
      "{'unscaled_linreg': 0.8592054386963557}\n",
      "{'unscaled_linreg': 3.726941696442016}\n"
     ]
    }
   ],
   "source": [
    "## It seems our best performance with a linear regressor was with the unscaled X_train with vanilla linear regression.\n",
    "## Let's check and save its performance on the validation set\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "valid_r2 = {}\n",
    "valid_rmse = {}\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "predictions = linreg.predict(X_valid)\n",
    "\n",
    "valid_r2[\"unscaled_linreg\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"unscaled_linreg\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(\"Linear regression's performance on the validation set:\")\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\n",
      "0.8759719138745785\n",
      "3.619740875293807\n"
     ]
    }
   ],
   "source": [
    "## Now let's see how a random forest performs on this data, and this can also give us some idea of feature importances\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "print(\"Random forest:\")\n",
    "print(cross_val_score(estimator=forest, X=X_train, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=forest, X=X_train, y=y_train, scoring=\"neg_mean_squared_error\", cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00218614, 0.00255499, 0.00267956, 0.00432479, 0.00281835,\n",
       "       0.00174957, 0.00158875, 0.00179831, 0.00247225, 0.00269799,\n",
       "       0.00275604, 0.00195806, 0.00146929, 0.00309955, 0.        ,\n",
       "       0.        , 0.57607372, 0.00639669, 0.00196505, 0.00217788,\n",
       "       0.005652  , 0.00432249, 0.20044678, 0.01199845, 0.00324895,\n",
       "       0.00315159, 0.0021525 , 0.00510636, 0.00357126, 0.00366679,\n",
       "       0.00424451, 0.00433272, 0.00265586, 0.00400614, 0.00311076,\n",
       "       0.00497131, 0.00273008, 0.        , 0.00133011, 0.00872881,\n",
       "       0.00506755, 0.00279782, 0.00523709, 0.0030801 , 0.00295414,\n",
       "       0.04679625, 0.00310661, 0.00337593, 0.00234871, 0.00249449,\n",
       "       0.00185137, 0.0023738 , 0.        , 0.        , 0.00497006,\n",
       "       0.00869577, 0.00465585])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Wow, this is very promising! Out of the box, the random forest does better on cross validation than linear regression\n",
    "## Now, let's see the model's feature importances\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>psa_00</th>\n",
       "      <td>0.576074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_00</th>\n",
       "      <td>0.200447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pw_00</th>\n",
       "      <td>0.046796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lln_00</th>\n",
       "      <td>0.011998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg_00</th>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_importance\n",
       "psa_00            0.576074\n",
       "car_00            0.200447\n",
       "pw_00             0.046796\n",
       "lln_00            0.011998\n",
       "pg_00             0.008729"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = {feature: importance for feature, importance in zip(X_train.columns, forest.feature_importances_)}\n",
    "feature_importances = pd.DataFrame.from_dict(importances, orient='index', columns=[\"feature_importance\"])\n",
    "feature_importances.sort_values(\"feature_importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let's try using grid search to optimize the random forest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "forestgrid = {\n",
    "    \"n_estimators\": [10, 50, 100, 1000, 10000],\n",
    "    \"max_depth\": [3, 4, 5, 6, None],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "grid = GridSearchCV(estimator=forest, param_grid=forestgrid, scoring=\"r2\", n_jobs=-1, verbose=2, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 30.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [3, 4, 5, 6, None],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [10, 50, 100, 1000, 10000]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 10000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765206234057411"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unscaled_linreg': 0.8592054386963557, 'optimized_forest': 0.890151415449202}\n",
      "{'unscaled_linreg': 3.726941696442016, 'optimized_forest': 3.2919777553369}\n"
     ]
    }
   ],
   "source": [
    "grid.best_estimator_.fit(X_train, y_train)\n",
    "predictions = grid.best_estimator_.predict(X_valid)\n",
    "\n",
    "valid_r2[\"optimized_forest\"] = r2_score(y_valid, predictions)\n",
    "valid_rmse[\"optimized_forest\"] = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "\n",
    "print(valid_r2)\n",
    "print(valid_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8574056842129044\n",
      "3.914679087104853\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svreg = svm.SVR(kernel='linear')\n",
    "\n",
    "print(cross_val_score(estimator=svreg, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())\n",
    "print(np.sqrt(-cross_val_score(estimator=svreg, X=X_train_robscale, y=y_train, scoring=\"neg_mean_squared_error\", cv=5).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884751050192833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=1000)\n",
    "\n",
    "print(cross_val_score(estimator=gb, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85538074694879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "psr = PoissonRegressor(alpha=0.5)\n",
    "\n",
    "print(cross_val_score(estimator=psr, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576030284557467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rid = Ridge()\n",
    "\n",
    "print(cross_val_score(estimator=rid, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576069179706138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "bayrid = BayesianRidge()\n",
    "\n",
    "print(cross_val_score(estimator=bayrid, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8834407146641056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "estimator_bagging_random_tree_1000 = BaggingRegressor(n_estimators=1000,\n",
    "                                    base_estimator=ExtraTreeRegressor())\n",
    "print(cross_val_score(estimator=estimator_bagging_random_tree_1000, X=X_train_robscale, y=y_train, scoring=\"r2\", cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
